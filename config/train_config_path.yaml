# YAML config for dataset, training, and model parameters

# Dataset parameters
dataset:
  n_flows_list: [20000]
  n_hosts_list: [3]
  shard: 0
  shard_list: [0,500,500] # [start, end, num]
  sample_list: [0,20,20] # [start, end, num]
  lr: 10
  bucket_thold: 1
  train_frac: 0.95
  enable_context: True
  topo_type: "_topo-pl-x_"
  # n_params: 35
  n_params: 98
  test_cc: "dctcp"
  # test_cc: "cubic"
  # test_cc: "hp95ai1000"
  # test_cc: "timely_vwin"
  # test_cc: "vegas"
  # test_cc: "bbr"
  train_on_param: 0

# Model parameters
model:
  model_name: "transformer"
  n_layer: 4
  n_head: 4
  n_embd: 576 
  block_size: 16
  vocab_size: 200 #50257
  dropout: 0.2
  compile: False 
  loss_fn_type: "l1"
  hidden_dims: [512,512]
  enable_position: True

# Training parameters
training:
  # gpu: [0,0,1,1,2,2,3,3]
  gpu: [0,1,2,3]
  n_epochs: 500
  batch_size: 10
  learning_rate: 0.0001
  betas: [0.9, 0.95]
  weight_decay: 0.02 
  num_workers: 5
  enable_val: True
  enable_dist: True
  enable_masked_loss: True
  enable_weighted_loss: False
  enable_log: False